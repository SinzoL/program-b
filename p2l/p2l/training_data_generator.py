#!/usr/bin/env python3
"""
P2Lè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
ç”Ÿæˆç”¨äºè®­ç»ƒP2Læ¨¡å‹çš„prompt-modelæ€§èƒ½é…å¯¹æ•°æ®
"""

import json
import random
import numpy as np
from typing import Dict, List, Tuple
import os
from datasets import Dataset
import logging

logger = logging.getLogger(__name__)

class P2LTrainingDataGenerator:
    """P2Lè®­ç»ƒæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.task_templates = self._load_task_templates()
        self.model_performance_profiles = self._load_model_profiles()
        
    def _load_task_templates(self) -> Dict:
        """åŠ è½½ä»»åŠ¡æ¨¡æ¿"""
        return {
            "ç¼–ç¨‹": [
                "å†™ä¸€ä¸ª{language}å‡½æ•°æ¥{function_desc}",
                "å®ç°{algorithm}ç®—æ³•çš„{language}ä»£ç ",
                "åˆ›å»ºä¸€ä¸ª{language}ç±»æ¥{class_desc}",
                "ç¼–å†™{language}ä»£ç è§£å†³{problem_desc}é—®é¢˜",
                "ä¼˜åŒ–è¿™æ®µ{language}ä»£ç ï¼š{code_snippet}",
                "è°ƒè¯•è¿™ä¸ª{language}ç¨‹åºä¸­çš„é”™è¯¯",
                "è®¾è®¡ä¸€ä¸ª{language}APIæ¥{api_desc}",
                "ç¼–å†™å•å…ƒæµ‹è¯•æ¥éªŒè¯{function_name}å‡½æ•°"
            ],
            "åˆ›æ„å†™ä½œ": [
                "å†™ä¸€ç¯‡å…³äº{topic}çš„{style}",
                "åˆ›ä½œä¸€é¦–{theme}çš„è¯—æ­Œ",
                "ç¼–å†™ä¸€ä¸ª{genre}æ•…äº‹ï¼Œä¸»é¢˜æ˜¯{theme}",
                "å†™ä¸€æ®µ{tone}çš„{content_type}",
                "åˆ›ä½œä¸€ä¸ª{character}çš„è§’è‰²æè¿°",
                "å†™ä¸€ç¯‡{length}çš„{topic}æ–‡ç« ",
                "ç¼–å†™ä¸€ä¸ª{setting}èƒŒæ™¯çš„åœºæ™¯æè¿°",
                "åˆ›ä½œä¸€ä¸ª{emotion}æƒ…æ„Ÿçš„{format}ä½œå“"
            ],
            "ç¿»è¯‘": [
                "å°†è¿™æ®µ{source_lang}ç¿»è¯‘æˆ{target_lang}ï¼š{text}",
                "ç¿»è¯‘è¿™ä¸ª{domain}é¢†åŸŸçš„{source_lang}æ–‡æ¡£",
                "æŠŠè¿™å¥{source_lang}è°šè¯­ç¿»è¯‘æˆ{target_lang}",
                "ç¿»è¯‘è¿™æ®µ{style}{source_lang}æ–‡æœ¬",
                "å°†{source_lang}çš„{content_type}ç¿»è¯‘æˆ{target_lang}",
                "ç¿»è¯‘è¿™ä¸ª{technical_field}çš„ä¸“ä¸šæœ¯è¯­",
                "æŠŠè¿™æ®µ{source_lang}å¯¹è¯ç¿»è¯‘æˆ{target_lang}",
                "ç¿»è¯‘è¿™é¦–{source_lang}è¯—æ­Œï¼Œä¿æŒéŸµå¾‹"
            ],
            "æ•°å­¦": [
                "è§£è¿™ä¸ª{math_type}æ–¹ç¨‹ï¼š{equation}",
                "è®¡ç®—{calculation_type}ï¼š{expression}",
                "è¯æ˜è¿™ä¸ª{theorem_type}å®šç†",
                "æ±‚è§£è¿™ä¸ª{problem_type}é—®é¢˜",
                "åˆ†æè¿™ä¸ª{function_type}å‡½æ•°çš„æ€§è´¨",
                "è®¡ç®—{geometry_shape}çš„{property}",
                "è§£é‡Š{concept}çš„æ•°å­¦åŸç†",
                "æ±‚{optimization_type}çš„æœ€ä¼˜è§£"
            ],
            "åˆ†æ": [
                "åˆ†æ{topic}çš„{aspect}",
                "è§£é‡Š{phenomenon}çš„åŸå› ",
                "è¯„ä¼°{subject}çš„{criteria}",
                "æ¯”è¾ƒ{item1}å’Œ{item2}çš„{dimension}",
                "æ€»ç»“{content}çš„è¦ç‚¹",
                "åˆ†æ{data_type}æ•°æ®çš„è¶‹åŠ¿",
                "è§£è¯»{chart_type}å›¾è¡¨çš„å«ä¹‰",
                "è¯„ä»·{work}çš„{evaluation_aspect}"
            ],
            "é—®ç­”": [
                "ä»€ä¹ˆæ˜¯{concept}ï¼Ÿ",
                "å¦‚ä½•{action}ï¼Ÿ",
                "ä¸ºä»€ä¹ˆ{phenomenon}ä¼šå‘ç”Ÿï¼Ÿ",
                "å“ªç§{category}æœ€{criteria}ï¼Ÿ",
                "ä»€ä¹ˆæ—¶å€™åº”è¯¥{action}ï¼Ÿ",
                "åœ¨å“ªé‡Œå¯ä»¥{find_what}ï¼Ÿ",
                "è°æ˜¯{field}é¢†åŸŸçš„{role}ï¼Ÿ",
                "{topic}æœ‰ä»€ä¹ˆ{aspect}ï¼Ÿ"
            ],
            "æ€»ç»“": [
                "æ€»ç»“è¿™ç¯‡{content_type}çš„ä¸»è¦è§‚ç‚¹",
                "æ¦‚æ‹¬{topic}çš„æ ¸å¿ƒå†…å®¹",
                "æç‚¼{document}çš„å…³é”®ä¿¡æ¯",
                "å½’çº³{discussion}çš„è¦ç‚¹",
                "ç®€è¿°{process}çš„æ­¥éª¤",
                "æ¦‚è¦{report}çš„ç»“è®º",
                "æ€»ç»“{meeting}çš„å†³è®®",
                "æ¢³ç†{topic}çš„å‘å±•å†ç¨‹"
            ],
            "é€šç”¨": [
                "å¸®æˆ‘{general_task}",
                "è¯·{polite_request}",
                "æˆ‘æƒ³äº†è§£{topic}",
                "èƒ½å¦{capability_request}",
                "å…³äº{subject}ï¼Œä½ æ€ä¹ˆçœ‹ï¼Ÿ",
                "ç»™æˆ‘ä¸€äº›{advice_type}å»ºè®®",
                "æ¨èä¸€äº›{recommendation_type}",
                "è§£é‡Šä¸€ä¸‹{explanation_target}"
            ]
        }
    
    def _load_model_profiles(self) -> Dict:
        """åŠ è½½æ¨¡å‹æ€§èƒ½æ¡£æ¡ˆ"""
        return {
            "gpt-4o": {
                "ç¼–ç¨‹": {"quality": 0.95, "speed": 0.7, "cost": 0.3},
                "åˆ›æ„å†™ä½œ": {"quality": 0.90, "speed": 0.7, "cost": 0.3},
                "ç¿»è¯‘": {"quality": 0.88, "speed": 0.7, "cost": 0.3},
                "æ•°å­¦": {"quality": 0.93, "speed": 0.7, "cost": 0.3},
                "åˆ†æ": {"quality": 0.92, "speed": 0.7, "cost": 0.3},
                "é—®ç­”": {"quality": 0.89, "speed": 0.7, "cost": 0.3},
                "æ€»ç»“": {"quality": 0.87, "speed": 0.7, "cost": 0.3},
                "é€šç”¨": {"quality": 0.90, "speed": 0.7, "cost": 0.3}
            },
            "gpt-4o-mini": {
                "ç¼–ç¨‹": {"quality": 0.82, "speed": 0.9, "cost": 0.95},
                "åˆ›æ„å†™ä½œ": {"quality": 0.78, "speed": 0.9, "cost": 0.95},
                "ç¿»è¯‘": {"quality": 0.80, "speed": 0.9, "cost": 0.95},
                "æ•°å­¦": {"quality": 0.79, "speed": 0.9, "cost": 0.95},
                "åˆ†æ": {"quality": 0.81, "speed": 0.9, "cost": 0.95},
                "é—®ç­”": {"quality": 0.85, "speed": 0.9, "cost": 0.95},
                "æ€»ç»“": {"quality": 0.83, "speed": 0.9, "cost": 0.95},
                "é€šç”¨": {"quality": 0.82, "speed": 0.9, "cost": 0.95}
            },
            "claude-3-5-sonnet-20241022": {
                "ç¼–ç¨‹": {"quality": 0.88, "speed": 0.6, "cost": 0.4},
                "åˆ›æ„å†™ä½œ": {"quality": 0.95, "speed": 0.6, "cost": 0.4},
                "ç¿»è¯‘": {"quality": 0.85, "speed": 0.6, "cost": 0.4},
                "æ•°å­¦": {"quality": 0.86, "speed": 0.6, "cost": 0.4},
                "åˆ†æ": {"quality": 0.93, "speed": 0.6, "cost": 0.4},
                "é—®ç­”": {"quality": 0.87, "speed": 0.6, "cost": 0.4},
                "æ€»ç»“": {"quality": 0.90, "speed": 0.6, "cost": 0.4},
                "é€šç”¨": {"quality": 0.89, "speed": 0.6, "cost": 0.4}
            },
            "claude-3-7-sonnet-20250219": {
                "ç¼–ç¨‹": {"quality": 0.92, "speed": 0.65, "cost": 0.4},
                "åˆ›æ„å†™ä½œ": {"quality": 0.97, "speed": 0.65, "cost": 0.4},
                "ç¿»è¯‘": {"quality": 0.88, "speed": 0.65, "cost": 0.4},
                "æ•°å­¦": {"quality": 0.89, "speed": 0.65, "cost": 0.4},
                "åˆ†æ": {"quality": 0.95, "speed": 0.65, "cost": 0.4},
                "é—®ç­”": {"quality": 0.90, "speed": 0.65, "cost": 0.4},
                "æ€»ç»“": {"quality": 0.92, "speed": 0.65, "cost": 0.4},
                "é€šç”¨": {"quality": 0.91, "speed": 0.65, "cost": 0.4}
            },
            "claude-3-5-haiku-20241022": {
                "ç¼–ç¨‹": {"quality": 0.80, "speed": 0.85, "cost": 0.8},
                "åˆ›æ„å†™ä½œ": {"quality": 0.82, "speed": 0.85, "cost": 0.8},
                "ç¿»è¯‘": {"quality": 0.78, "speed": 0.85, "cost": 0.8},
                "æ•°å­¦": {"quality": 0.76, "speed": 0.85, "cost": 0.8},
                "åˆ†æ": {"quality": 0.81, "speed": 0.85, "cost": 0.8},
                "é—®ç­”": {"quality": 0.84, "speed": 0.85, "cost": 0.8},
                "æ€»ç»“": {"quality": 0.86, "speed": 0.85, "cost": 0.8},
                "é€šç”¨": {"quality": 0.82, "speed": 0.85, "cost": 0.8}
            },
            "gemini-1.5-pro-002": {
                "ç¼–ç¨‹": {"quality": 0.87, "speed": 0.75, "cost": 0.5},
                "åˆ›æ„å†™ä½œ": {"quality": 0.85, "speed": 0.75, "cost": 0.5},
                "ç¿»è¯‘": {"quality": 0.88, "speed": 0.75, "cost": 0.5},
                "æ•°å­¦": {"quality": 0.90, "speed": 0.75, "cost": 0.5},
                "åˆ†æ": {"quality": 0.89, "speed": 0.75, "cost": 0.5},
                "é—®ç­”": {"quality": 0.86, "speed": 0.75, "cost": 0.5},
                "æ€»ç»“": {"quality": 0.84, "speed": 0.75, "cost": 0.5},
                "é€šç”¨": {"quality": 0.87, "speed": 0.75, "cost": 0.5}
            },
            "gemini-1.5-flash-002": {
                "ç¼–ç¨‹": {"quality": 0.75, "speed": 0.95, "cost": 0.9},
                "åˆ›æ„å†™ä½œ": {"quality": 0.73, "speed": 0.95, "cost": 0.9},
                "ç¿»è¯‘": {"quality": 0.76, "speed": 0.95, "cost": 0.9},
                "æ•°å­¦": {"quality": 0.78, "speed": 0.95, "cost": 0.9},
                "åˆ†æ": {"quality": 0.74, "speed": 0.95, "cost": 0.9},
                "é—®ç­”": {"quality": 0.80, "speed": 0.95, "cost": 0.9},
                "æ€»ç»“": {"quality": 0.82, "speed": 0.95, "cost": 0.9},
                "é€šç”¨": {"quality": 0.77, "speed": 0.95, "cost": 0.9}
            },
            "qwen2.5-72b-instruct": {
                "ç¼–ç¨‹": {"quality": 0.85, "speed": 0.8, "cost": 0.7},
                "åˆ›æ„å†™ä½œ": {"quality": 0.90, "speed": 0.8, "cost": 0.7},
                "ç¿»è¯‘": {"quality": 0.92, "speed": 0.8, "cost": 0.7},
                "æ•°å­¦": {"quality": 0.83, "speed": 0.8, "cost": 0.7},
                "åˆ†æ": {"quality": 0.87, "speed": 0.8, "cost": 0.7},
                "é—®ç­”": {"quality": 0.88, "speed": 0.8, "cost": 0.7},
                "æ€»ç»“": {"quality": 0.86, "speed": 0.8, "cost": 0.7},
                "é€šç”¨": {"quality": 0.87, "speed": 0.8, "cost": 0.7}
            },
            "llama-3.1-70b-instruct": {
                "ç¼–ç¨‹": {"quality": 0.84, "speed": 0.7, "cost": 0.8},
                "åˆ›æ„å†™ä½œ": {"quality": 0.81, "speed": 0.7, "cost": 0.8},
                "ç¿»è¯‘": {"quality": 0.79, "speed": 0.7, "cost": 0.8},
                "æ•°å­¦": {"quality": 0.82, "speed": 0.7, "cost": 0.8},
                "åˆ†æ": {"quality": 0.83, "speed": 0.7, "cost": 0.8},
                "é—®ç­”": {"quality": 0.85, "speed": 0.7, "cost": 0.8},
                "æ€»ç»“": {"quality": 0.84, "speed": 0.7, "cost": 0.8},
                "é€šç”¨": {"quality": 0.83, "speed": 0.7, "cost": 0.8}
            },
            "deepseek-v3": {
                "ç¼–ç¨‹": {"quality": 0.89, "speed": 0.85, "cost": 0.75},
                "åˆ›æ„å†™ä½œ": {"quality": 0.78, "speed": 0.85, "cost": 0.75},
                "ç¿»è¯‘": {"quality": 0.80, "speed": 0.85, "cost": 0.75},
                "æ•°å­¦": {"quality": 0.91, "speed": 0.85, "cost": 0.75},
                "åˆ†æ": {"quality": 0.85, "speed": 0.85, "cost": 0.75},
                "é—®ç­”": {"quality": 0.82, "speed": 0.85, "cost": 0.75},
                "æ€»ç»“": {"quality": 0.81, "speed": 0.85, "cost": 0.75},
                "é€šç”¨": {"quality": 0.84, "speed": 0.85, "cost": 0.75}
            }
        }
    
    def generate_prompt(self, task_type: str, complexity: str = "ä¸­ç­‰", language: str = "ä¸­æ–‡") -> str:
        """ç”Ÿæˆç‰¹å®šç±»å‹çš„prompt"""
        templates = self.task_templates.get(task_type, self.task_templates["é€šç”¨"])
        template = random.choice(templates)
        
        # æ ¹æ®ä»»åŠ¡ç±»å‹å¡«å……æ¨¡æ¿
        if task_type == "ç¼–ç¨‹":
            return self._fill_programming_template(template, complexity, language)
        elif task_type == "åˆ›æ„å†™ä½œ":
            return self._fill_creative_template(template, complexity, language)
        elif task_type == "ç¿»è¯‘":
            return self._fill_translation_template(template, complexity, language)
        elif task_type == "æ•°å­¦":
            return self._fill_math_template(template, complexity, language)
        elif task_type == "åˆ†æ":
            return self._fill_analysis_template(template, complexity, language)
        elif task_type == "é—®ç­”":
            return self._fill_qa_template(template, complexity, language)
        elif task_type == "æ€»ç»“":
            return self._fill_summary_template(template, complexity, language)
        else:
            return self._fill_general_template(template, complexity, language)
    
    def _fill_programming_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……ç¼–ç¨‹æ¨¡æ¿"""
        languages = ["Python", "JavaScript", "Java", "C++", "Go"]
        functions = ["æ’åºæ•°ç»„", "æŸ¥æ‰¾å…ƒç´ ", "è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—", "åè½¬å­—ç¬¦ä¸²", "åˆå¹¶åˆ—è¡¨"]
        algorithms = ["å¿«é€Ÿæ’åº", "äºŒåˆ†æŸ¥æ‰¾", "åŠ¨æ€è§„åˆ’", "æ·±åº¦ä¼˜å…ˆæœç´¢", "å¹¿åº¦ä¼˜å…ˆæœç´¢"]
        
        replacements = {
            "language": random.choice(languages),
            "function_desc": random.choice(functions),
            "algorithm": random.choice(algorithms),
            "class_desc": "ç®¡ç†ç”¨æˆ·æ•°æ®",
            "problem_desc": "æœ€çŸ­è·¯å¾„",
            "code_snippet": "def func(): pass",
            "api_desc": "å¤„ç†HTTPè¯·æ±‚",
            "function_name": "calculate_sum"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_creative_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……åˆ›æ„å†™ä½œæ¨¡æ¿"""
        topics = ["æ˜¥å¤©", "å‹è°Š", "æ¢¦æƒ³", "å®¶ä¹¡", "æœªæ¥"]
        styles = ["æ•£æ–‡", "å°è¯´", "è¯—æ­Œ", "æ—¥è®°", "æ•…äº‹"]
        themes = ["çˆ±æƒ…", "æˆé•¿", "å†’é™©", "å‹è°Š", "å¸Œæœ›"]
        
        replacements = {
            "topic": random.choice(topics),
            "style": random.choice(styles),
            "theme": random.choice(themes),
            "genre": "ç§‘å¹»",
            "tone": "æ¸©æš–",
            "content_type": "çŸ­æ–‡",
            "character": "å‹‡æ•¢çš„æ¢é™©å®¶",
            "length": "500å­—",
            "setting": "æœªæ¥ä¸–ç•Œ",
            "emotion": "å–œæ‚¦",
            "format": "è¯—æ­Œ"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_translation_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……ç¿»è¯‘æ¨¡æ¿"""
        source_langs = ["è‹±æ–‡", "ä¸­æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡"]
        target_langs = ["ä¸­æ–‡", "è‹±æ–‡", "æ—¥æ–‡", "æ³•æ–‡", "å¾·æ–‡"]
        
        replacements = {
            "source_lang": random.choice(source_langs),
            "target_lang": random.choice(target_langs),
            "text": "Hello, how are you?",
            "domain": "æŠ€æœ¯",
            "style": "æ­£å¼",
            "content_type": "æ–‡æ¡£",
            "technical_field": "è®¡ç®—æœºç§‘å­¦"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_math_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……æ•°å­¦æ¨¡æ¿"""
        math_types = ["çº¿æ€§", "äºŒæ¬¡", "ä¸‰è§’", "æŒ‡æ•°", "å¯¹æ•°"]
        expressions = ["2x + 3 = 7", "xÂ² - 5x + 6 = 0", "sin(x) = 0.5"]
        
        replacements = {
            "math_type": random.choice(math_types),
            "equation": random.choice(expressions),
            "calculation_type": "ç§¯åˆ†",
            "expression": "âˆ«xÂ²dx",
            "theorem_type": "å‹¾è‚¡",
            "problem_type": "ä¼˜åŒ–",
            "function_type": "äºŒæ¬¡",
            "geometry_shape": "åœ†å½¢",
            "property": "é¢ç§¯",
            "concept": "å¯¼æ•°",
            "optimization_type": "çº¿æ€§è§„åˆ’"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_analysis_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……åˆ†ææ¨¡æ¿"""
        topics = ["å¸‚åœºè¶‹åŠ¿", "ç”¨æˆ·è¡Œä¸º", "æŠ€æœ¯å‘å±•", "ç»æµå½¢åŠ¿", "ç¤¾ä¼šç°è±¡"]
        aspects = ["ä¼˜åŠ¿", "åŠ£åŠ¿", "æœºä¼š", "å¨èƒ", "ç‰¹ç‚¹"]
        
        replacements = {
            "topic": random.choice(topics),
            "aspect": random.choice(aspects),
            "phenomenon": "é€šèƒ€",
            "subject": "æ–°äº§å“",
            "criteria": "æ€§ä»·æ¯”",
            "item1": "æ–¹æ¡ˆA",
            "item2": "æ–¹æ¡ˆB",
            "dimension": "æˆæœ¬æ•ˆç›Š",
            "content": "æŠ¥å‘Šå†…å®¹",
            "data_type": "é”€å”®",
            "chart_type": "æŸ±çŠ¶",
            "work": "è¿™éƒ¨ä½œå“",
            "evaluation_aspect": "è‰ºæœ¯ä»·å€¼"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_qa_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……é—®ç­”æ¨¡æ¿"""
        concepts = ["äººå·¥æ™ºèƒ½", "åŒºå—é“¾", "é‡å­è®¡ç®—", "æœºå™¨å­¦ä¹ ", "äº‘è®¡ç®—"]
        actions = ["å­¦ä¹ ç¼–ç¨‹", "æé«˜æ•ˆç‡", "ç®¡ç†æ—¶é—´", "ä¿æŒå¥åº·", "æŠ•èµ„ç†è´¢"]
        
        replacements = {
            "concept": random.choice(concepts),
            "action": random.choice(actions),
            "phenomenon": "å…¨çƒå˜æš–",
            "category": "ç¼–ç¨‹è¯­è¨€",
            "criteria": "é€‚åˆåˆå­¦è€…",
            "find_what": "å­¦ä¹ èµ„æº",
            "field": "ç§‘æŠ€",
            "role": "é¢†å¯¼è€…",
            "topic": "äººå·¥æ™ºèƒ½",
            "aspect": "åº”ç”¨å‰æ™¯"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_summary_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……æ€»ç»“æ¨¡æ¿"""
        content_types = ["æ–‡ç« ", "æŠ¥å‘Š", "è®ºæ–‡", "æ–°é—»", "ç ”ç©¶"]
        topics = ["æŠ€æœ¯å‘å±•", "å¸‚åœºåˆ†æ", "ç”¨æˆ·ç ”ç©¶", "äº§å“è¯„ä¼°", "è¡Œä¸šè¶‹åŠ¿"]
        
        replacements = {
            "content_type": random.choice(content_types),
            "topic": random.choice(topics),
            "document": "æŠ€æœ¯æ–‡æ¡£",
            "discussion": "ä¼šè®®è®¨è®º",
            "process": "å¼€å‘æµç¨‹",
            "report": "å­£åº¦æŠ¥å‘Š",
            "meeting": "é¡¹ç›®ä¼šè®®"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def _fill_general_template(self, template: str, complexity: str, language: str) -> str:
        """å¡«å……é€šç”¨æ¨¡æ¿"""
        tasks = ["è§£å†³é—®é¢˜", "åˆ¶å®šè®¡åˆ’", "å­¦ä¹ æ–°æŠ€èƒ½", "æ”¹è¿›æµç¨‹", "ä¼˜åŒ–æ€§èƒ½"]
        requests = ["å¸®åŠ©æˆ‘ç†è§£", "ç»™æˆ‘å»ºè®®", "æä¾›ä¿¡æ¯", "è§£é‡Šæ¦‚å¿µ", "åˆ†ææƒ…å†µ"]
        
        replacements = {
            "general_task": random.choice(tasks),
            "polite_request": random.choice(requests),
            "topic": "äººå·¥æ™ºèƒ½",
            "subject": "è¿™ä¸ªè¯é¢˜",
            "capability_request": "å¸®æˆ‘åˆ†æ",
            "advice_type": "å­¦ä¹ ",
            "recommendation_type": "ä¹¦ç±",
            "explanation_target": "è¿™ä¸ªæ¦‚å¿µ"
        }
        
        for key, value in replacements.items():
            template = template.replace(f"{{{key}}}", value)
        
        return template
    
    def calculate_model_performance(self, prompt: str, model: str, task_type: str, 
                                  complexity: str, priority: str = "performance") -> float:
        """è®¡ç®—æ¨¡å‹åœ¨ç‰¹å®špromptä¸Šçš„æ€§èƒ½åˆ†æ•°"""
        base_performance = self.model_performance_profiles[model][task_type]
        
        # åŸºç¡€åˆ†æ•°
        if priority == "performance":
            score = base_performance["quality"]
        elif priority == "speed":
            score = base_performance["speed"]
        elif priority == "cost":
            score = base_performance["cost"]
        else:  # balanced
            score = (base_performance["quality"] + base_performance["speed"] + base_performance["cost"]) / 3
        
        # å¤æ‚åº¦è°ƒæ•´
        if complexity == "å¤æ‚":
            if model in ["gpt-4o", "claude-3-5-sonnet-20241022", "claude-3-7-sonnet-20250219", "gemini-1.5-pro-002"]:
                score += 0.05  # é«˜ç«¯æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°æ›´å¥½
            else:
                score -= 0.03  # å…¶ä»–æ¨¡å‹åœ¨å¤æ‚ä»»åŠ¡ä¸Šè¡¨ç°ä¸‹é™
        elif complexity == "ç®€å•":
            if model in ["gpt-4o-mini", "claude-3-5-haiku-20241022", "gemini-1.5-flash-002"]:
                score += 0.03  # è½»é‡æ¨¡å‹åœ¨ç®€å•ä»»åŠ¡ä¸Šæ›´æœ‰ä¼˜åŠ¿
        
        # æ·»åŠ éšæœºå™ªå£°æ¨¡æ‹ŸçœŸå®åœºæ™¯
        noise = np.random.normal(0, 0.02)
        score = max(0.1, min(1.0, score + noise))
        
        return score
    
    def generate_training_sample(self) -> Dict:
        """ç”Ÿæˆä¸€ä¸ªè®­ç»ƒæ ·æœ¬"""
        # éšæœºé€‰æ‹©ä»»åŠ¡å‚æ•°
        task_type = random.choice(list(self.task_templates.keys()))
        complexity = random.choice(["ç®€å•", "ä¸­ç­‰", "å¤æ‚"])
        language = random.choice(["ä¸­æ–‡", "è‹±æ–‡"])
        priority = random.choice(["performance", "speed", "cost", "balanced"])
        
        # ç”Ÿæˆprompt
        prompt = self.generate_prompt(task_type, complexity, language)
        
        # è®¡ç®—æ‰€æœ‰æ¨¡å‹çš„æ€§èƒ½
        model_performances = {}
        for model in self.model_performance_profiles.keys():
            score = self.calculate_model_performance(prompt, model, task_type, complexity, priority)
            model_performances[model] = score
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = max(model_performances.items(), key=lambda x: x[1])
        
        # åˆ›å»ºæ ‡ç­¾ - å¤šåˆ†ç±»æ ‡ç­¾
        task_label = list(self.task_templates.keys()).index(task_type)
        complexity_label = ["ç®€å•", "ä¸­ç­‰", "å¤æ‚"].index(complexity)
        language_label = ["ä¸­æ–‡", "è‹±æ–‡"].index(language)
        
        # æ¨¡å‹æ’åæ ‡ç­¾
        sorted_models = sorted(model_performances.items(), key=lambda x: x[1], reverse=True)
        model_rankings = [model for model, _ in sorted_models]
        
        return {
            "prompt": prompt,
            "task_type": task_type,
            "task_label": task_label,
            "complexity": complexity,
            "complexity_label": complexity_label,
            "language": language,
            "language_label": language_label,
            "priority": priority,
            "best_model": best_model[0],
            "best_score": best_model[1],
            "model_performances": model_performances,
            "model_rankings": model_rankings,
            "labels": [task_label, complexity_label, language_label]  # å¤šä»»åŠ¡æ ‡ç­¾
        }
    
    def generate_dataset(self, num_samples: int = 10000, save_path: str = None) -> Dataset:
        """ç”Ÿæˆå®Œæ•´çš„è®­ç»ƒæ•°æ®é›†"""
        logger.info(f"ç”Ÿæˆ {num_samples} ä¸ªè®­ç»ƒæ ·æœ¬...")
        
        samples = []
        for i in range(num_samples):
            if i % 1000 == 0:
                logger.info(f"å·²ç”Ÿæˆ {i}/{num_samples} ä¸ªæ ·æœ¬")
            
            sample = self.generate_training_sample()
            samples.append(sample)
        
        # è½¬æ¢ä¸ºDatasetæ ¼å¼
        dataset_dict = {
            "prompt": [s["prompt"] for s in samples],
            "task_type": [s["task_type"] for s in samples],
            "task_label": [s["task_label"] for s in samples],
            "complexity": [s["complexity"] for s in samples],
            "complexity_label": [s["complexity_label"] for s in samples],
            "language": [s["language"] for s in samples],
            "language_label": [s["language_label"] for s in samples],
            "priority": [s["priority"] for s in samples],
            "best_model": [s["best_model"] for s in samples],
            "best_score": [s["best_score"] for s in samples],
            "labels": [s["labels"] for s in samples]
        }
        
        dataset = Dataset.from_dict(dataset_dict)
        
        if save_path:
            logger.info(f"ä¿å­˜æ•°æ®é›†åˆ°: {save_path}")
            dataset.save_to_disk(save_path)
            
            # åŒæ—¶ä¿å­˜JSONæ ¼å¼ç”¨äºæ£€æŸ¥
            with open(os.path.join(save_path, "samples.json"), "w", encoding="utf-8") as f:
                json.dump(samples[:100], f, ensure_ascii=False, indent=2)  # ä¿å­˜å‰100ä¸ªæ ·æœ¬ç”¨äºæ£€æŸ¥
        
        logger.info(f"âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆï¼Œå…± {len(dataset)} ä¸ªæ ·æœ¬")
        return dataset
    
    def generate_validation_dataset(self, num_samples: int = 2000, save_path: str = None) -> Dataset:
        """ç”ŸæˆéªŒè¯æ•°æ®é›†"""
        logger.info(f"ç”Ÿæˆ {num_samples} ä¸ªéªŒè¯æ ·æœ¬...")
        return self.generate_dataset(num_samples, save_path)

if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
    generator = P2LTrainingDataGenerator()
    
    # ç”Ÿæˆå°‘é‡æ ·æœ¬è¿›è¡Œæµ‹è¯•
    print("ğŸ§ª æµ‹è¯•æ ·æœ¬ç”Ÿæˆ...")
    for i in range(5):
        sample = generator.generate_training_sample()
        print(f"\næ ·æœ¬ {i+1}:")
        print(f"Prompt: {sample['prompt']}")
        print(f"ä»»åŠ¡ç±»å‹: {sample['task_type']}")
        print(f"å¤æ‚åº¦: {sample['complexity']}")
        print(f"è¯­è¨€: {sample['language']}")
        print(f"æœ€ä½³æ¨¡å‹: {sample['best_model']} (åˆ†æ•°: {sample['best_score']:.3f})")
    
    # ç”Ÿæˆå®Œæ•´æ•°æ®é›†
    print(f"\nğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®é›†...")
    train_dataset = generator.generate_dataset(
        num_samples=1000,  # æµ‹è¯•ç”¨å°æ•°æ®é›†
        save_path="./p2l_training_data"
    )
    
    print(f"\nğŸ“Š ç”ŸæˆéªŒè¯æ•°æ®é›†...")
    val_dataset = generator.generate_validation_dataset(
        num_samples=200,  # æµ‹è¯•ç”¨å°æ•°æ®é›†
        save_path="./p2l_validation_data"
    )
    
    print(f"\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆ!")
    print(f"è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")