#!/usr/bin/env python3
"""
æµ‹è¯•åƒé—®APIé›†æˆ
éªŒè¯åƒé—®æ¨¡å‹åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„é›†æˆæƒ…å†µ
"""

import asyncio
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(__file__))

async def test_qwen_llm_client():
    """æµ‹è¯•LLMå®¢æˆ·ç«¯ä¸­çš„åƒé—®æ”¯æŒ"""
    print("ğŸ§ª æµ‹è¯•LLMå®¢æˆ·ç«¯ä¸­çš„åƒé—®æ”¯æŒ...")
    
    try:
        from llm_client import LLMClient
        
        async with LLMClient() as client:
            response = await client.generate_response(
                model='qwen2.5-72b-instruct',
                prompt='ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±',
                max_tokens=200
            )
            
            print(f"âœ… LLMå®¢æˆ·ç«¯æµ‹è¯•æˆåŠŸ")
            print(f"ğŸ“ å“åº”: {response.content[:100]}...")
            print(f"ğŸ“Š Tokenæ•°: {response.tokens_used}, æˆæœ¬: ${response.cost:.4f}")
            print(f"ğŸ·ï¸ æä¾›å•†: {response.provider}")
            return True
            
    except Exception as e:
        print(f"âŒ LLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_simple_qwen_client():
    """æµ‹è¯•ç®€å•åƒé—®å®¢æˆ·ç«¯"""
    print("\nğŸ§ª æµ‹è¯•ç®€å•åƒé—®å®¢æˆ·ç«¯...")
    
    try:
        from simple_qwen_client import SimpleQwenClient
        
        client = SimpleQwenClient()
        if not client.api_key:
            print("âŒ åƒé—®APIå¯†é’¥æœªé…ç½®")
            return False
            
        response = client.generate_response(
            model='qwen2.5-72b-instruct',
            prompt='å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—',
            max_tokens=300
        )
        
        print(f"âœ… ç®€å•å®¢æˆ·ç«¯æµ‹è¯•æˆåŠŸ")
        print(f"ğŸ“ å“åº”: {response['content'][:100]}...")
        print(f"ğŸ“Š Tokenæ•°: {response['tokens']}, æˆæœ¬: ${response['cost']:.4f}")
        print(f"ğŸ·ï¸ æä¾›å•†: {response['provider']}")
        return True
        
    except Exception as e:
        print(f"âŒ ç®€å•å®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_backend_service_config():
    """æµ‹è¯•åç«¯æœåŠ¡é…ç½®"""
    print("\nğŸ§ª æµ‹è¯•åç«¯æœåŠ¡é…ç½®...")
    
    try:
        from backend_service import P2LBackendService
        
        service = P2LBackendService()
        
        # æ£€æŸ¥åƒé—®æ¨¡å‹é…ç½®
        qwen_models = [model for model in service.model_configs.keys() if model.startswith('qwen')]
        
        if qwen_models:
            print(f"âœ… å‘ç°åƒé—®æ¨¡å‹é…ç½®: {qwen_models}")
            
            for model in qwen_models:
                config = service.model_configs[model]
                print(f"ğŸ“‹ {model}: æä¾›å•†={config['provider']}, æˆæœ¬=${config['cost_per_1k']}/1K tokens")
            
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°åƒé—®æ¨¡å‹é…ç½®")
            return False
            
    except Exception as e:
        print(f"âŒ åç«¯æœåŠ¡é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_p2l_inference_config():
    """æµ‹è¯•P2Læ¨ç†å¼•æ“é…ç½®"""
    print("\nğŸ§ª æµ‹è¯•P2Læ¨ç†å¼•æ“é…ç½®...")
    
    try:
        from p2l.p2l_inference import P2LInferenceEngine
        
        # åˆ›å»ºæ¨ç†å¼•æ“å®ä¾‹
        engine = P2LInferenceEngine()
        
        # æ£€æŸ¥åƒé—®æ¨¡å‹é…ç½®
        qwen_models = [model for model in engine.model_configs.keys() if model.startswith('qwen')]
        
        if qwen_models:
            print(f"âœ… P2Læ¨ç†å¼•æ“ä¸­å‘ç°åƒé—®æ¨¡å‹: {qwen_models}")
            
            for model in qwen_models:
                config = engine.model_configs[model]
                print(f"ğŸ“‹ {model}: æä¾›å•†={config['provider']}, è´¨é‡åˆ†æ•°={config['quality_score']}")
            
            return True
        else:
            print("âŒ P2Læ¨ç†å¼•æ“ä¸­æœªæ‰¾åˆ°åƒé—®æ¨¡å‹é…ç½®")
            return False
            
    except Exception as e:
        print(f"âŒ P2Læ¨ç†å¼•æ“é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åƒé—®APIé›†æˆæµ‹è¯•...\n")
    
    results = []
    
    # æµ‹è¯•ç®€å•å®¢æˆ·ç«¯
    results.append(test_simple_qwen_client())
    
    # æµ‹è¯•LLMå®¢æˆ·ç«¯
    results.append(await test_qwen_llm_client())
    
    # æµ‹è¯•åç«¯æœåŠ¡é…ç½®
    results.append(test_backend_service_config())
    
    # æµ‹è¯•P2Læ¨ç†å¼•æ“é…ç½®
    results.append(test_p2l_inference_config())
    
    # æ±‡æ€»ç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    print(f"âœ… æˆåŠŸ: {sum(results)}/{len(results)}")
    print(f"âŒ å¤±è´¥: {len(results) - sum(results)}/{len(results)}")
    
    if all(results):
        print("\nğŸ‰ åƒé—®APIé›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")

if __name__ == "__main__":
    asyncio.run(main())