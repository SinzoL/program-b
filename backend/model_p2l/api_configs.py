#!/usr/bin/env python3
"""
APIé…ç½®æ–‡ä»¶ - é¡¹ç›®å¤–å±‚é…ç½®
åŒ…å«æ‰€æœ‰APIå¯†é’¥å’Œç«¯ç‚¹é…ç½®ï¼Œä¾›backendæ¨¡å—ä½¿ç”¨
åŸºäºAPIæµ‹è¯•ç»“æœæ›´æ–° (2025-01-06)

é‡æ„è¯´æ˜ï¼š
- APIå¯†é’¥å·²ç§»è‡³ api_key.env æ–‡ä»¶ä¸­
- æ”¯æŒä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
- æä¾›é»˜è®¤å€¼ä»¥ä¿è¯ç³»ç»Ÿç¨³å®šæ€§
"""

import os
from pathlib import Path
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶
env_path = Path(__file__).parent / "api_key.env"
if env_path.exists():
    load_dotenv(env_path)
    print(f"âœ… å·²åŠ è½½ç¯å¢ƒé…ç½®: {env_path}")
else:
    print(f"âš ï¸ ç¯å¢ƒé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {env_path}")
    print("ğŸ“‹ è¯·å¤åˆ¶ api_key.env.example ä¸º api_key.env å¹¶é…ç½®ä½ çš„APIå¯†é’¥")

# ================== APIé…ç½® ==================
API_CONFIGS = {
    # APIå¯†é’¥é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–
    "api_keys": {
        "openai": os.getenv("OPENAI_API_KEY"),
        "anthropic": os.getenv("ANTHROPIC_API_KEY"),
        "google": os.getenv("GOOGLE_API_KEY"),
        "deepseek": os.getenv("DEEPSEEK_API_KEY"),
        "meta": os.getenv("META_API_KEY"),
        "dashscope": os.getenv("DASHSCOPE_API_KEY"),
    },
    
    # APIç«¯ç‚¹é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæä¾›é»˜è®¤å€¼
    "base_urls": {
        "openai": os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1"),
        "anthropic": os.getenv("ANTHROPIC_BASE_URL", "https://api.anthropic.com"),
        "google": os.getenv("GOOGLE_BASE_URL", "https://generativelanguage.googleapis.com/v1beta"),
        "deepseek": os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com/v1"),
        "meta": os.getenv("META_BASE_URL", "https://api.meta.com/v1"),
        "dashscope": os.getenv("DASHSCOPE_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1"),
    },
    
    # è¯·æ±‚è¶…æ—¶é…ç½®
    "timeouts": {
        "connect": 30,
        "total": 180,  # å¢åŠ åˆ°180ç§’ï¼Œé€‚åº”å¤æ‚ç¼–ç¨‹é—®é¢˜
        "read": 150    # å¢åŠ è¯»å–è¶…æ—¶
    },
    
    # è¿æ¥æ± é…ç½®
    "connection_pool": {
        "limit": 100,
        "limit_per_host": 30,
        "ttl_dns_cache": 300
    }
}

# ================== ä»»åŠ¡åˆ†æé…ç½® ==================
TASK_ANALYSIS_CONFIG = {
    # ä»»åŠ¡ç±»å‹æƒé‡
    "task_weights": {
        "coding": {
            "quality_weight": 0.4,
            "speed_weight": 0.3,
            "cost_weight": 0.3
        },
        "creative": {
            "quality_weight": 0.6,
            "speed_weight": 0.2,
            "cost_weight": 0.2
        },
        "analysis": {
            "quality_weight": 0.5,
            "speed_weight": 0.3,
            "cost_weight": 0.2
        },
        "conversation": {
            "quality_weight": 0.3,
            "speed_weight": 0.4,
            "cost_weight": 0.3
        },
        "translation": {
            "quality_weight": 0.4,
            "speed_weight": 0.4,
            "cost_weight": 0.2
        }
    },
    
    # å¤æ‚åº¦é˜ˆå€¼
    "complexity_thresholds": {
        "simple": 0.3,
        "medium": 0.6,
        "complex": 0.8
    },
    
    # è¯­è¨€æ£€æµ‹å…³é”®è¯
    "language_keywords": {
        "chinese": ["ä¸­æ–‡", "æ±‰è¯­", "æ™®é€šè¯", "ç®€ä½“", "ç¹ä½“", "ä¸­å›½", "ç¿»è¯‘æˆä¸­æ–‡"],
        "english": ["english", "translate to english", "in english"],
        "code": ["ä»£ç ", "ç¼–ç¨‹", "å‡½æ•°", "class", "def", "import", "return", "if", "for", "while"]
    }
}

# ================== æœåŠ¡é…ç½® ==================
SERVICE_CONFIG = {
    # æœåŠ¡å™¨é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œæä¾›é»˜è®¤å€¼
    "server": {
        "host": os.getenv("P2L_HOST", "0.0.0.0"),
        "port": int(os.getenv("P2L_PORT", "8080")),
        "log_level": os.getenv("P2L_LOG_LEVEL", "info"),
        "reload": os.getenv("P2L_RELOAD", "false").lower() == "true"
    },
    
    # CORSé…ç½®
    "cors": {
        "allow_origins": ["*"],
        "allow_credentials": True,
        "allow_methods": ["*"],
        "allow_headers": ["*"]
    },
    
    # æ—¥å¿—é…ç½®
    "logging": {
        "level": "INFO",
        "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    }
}

# ================== é»˜è®¤é…ç½® ==================
DEFAULT_CONFIG = {
    "DEFAULT_MODEL": os.getenv("DEFAULT_MODEL", "gpt-4o-mini"),
    "MAX_TOKENS": int(os.getenv("MAX_TOKENS", "2000")),
    "TEMPERATURE": float(os.getenv("TEMPERATURE", "0.7"))
}

# ================== å·¥å…·å‡½æ•° ==================
def load_env_config(env_file_path: str = None) -> None:
    """ä»ç¯å¢ƒé…ç½®æ–‡ä»¶åŠ è½½é…ç½® (ä¿æŒå…¼å®¹æ€§ï¼Œä½†ä¸»è¦é…ç½®å·²ç›´æ¥å†™å…¥)"""
    # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä¿æŒå…¼å®¹æ€§
    for provider, key in API_CONFIGS["api_keys"].items():
        if key:
            os.environ[f"{provider.upper()}_API_KEY"] = key
    
    for provider, url in API_CONFIGS["base_urls"].items():
        if url:
            os.environ[f"{provider.upper()}_BASE_URL"] = url
    
    # è®¾ç½®é»˜è®¤é…ç½®
    for key, value in DEFAULT_CONFIG.items():
        os.environ[key] = str(value)

def get_default_config():
    """è·å–é»˜è®¤é…ç½®"""
    return DEFAULT_CONFIG

def get_api_config():
    """è·å–APIé…ç½®"""
    return API_CONFIGS

def get_task_config():
    """è·å–ä»»åŠ¡åˆ†æé…ç½®"""
    return TASK_ANALYSIS_CONFIG

def get_service_config():
    """è·å–æœåŠ¡é…ç½®"""
    return SERVICE_CONFIG

# åˆå§‹åŒ–æ—¶åŠ è½½ç¯å¢ƒé…ç½®
load_env_config()

if __name__ == "__main__":
    print("âœ… APIé…ç½®åŠ è½½å®Œæˆ")
    print(f"ğŸ“‹ é…ç½®çš„APIæä¾›å•†:")
    for provider, key in API_CONFIGS["api_keys"].items():
        status = "âœ… å·²é…ç½®" if key else "âŒ æœªé…ç½®"
        print(f"  - {provider}: {status}")
    
    print(f"\nğŸ“‹ é»˜è®¤é…ç½®:")
    for key, value in DEFAULT_CONFIG.items():
        print(f"  - {key}: {value}")