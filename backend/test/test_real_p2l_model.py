#!/usr/bin/env python3
"""
æµ‹è¯•çœŸå®P2Læ¨¡å‹å¼•æ“
ä½¿ç”¨ä¸‹è½½çš„p2l-135m-grkæ¨¡å‹è¿›è¡ŒBradley-Terryç³»æ•°è®¡ç®—
"""

import asyncio
import json
import sys
import os
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, backend_dir)

# æ·»åŠ p2lé¡¹ç›®è·¯å¾„
p2l_dir = os.path.join(os.path.dirname(backend_dir), 'p2l')
sys.path.insert(0, p2l_dir)

async def test_real_p2l_model():
    """æµ‹è¯•çœŸå®P2Læ¨¡å‹çš„å®Œæ•´æµç¨‹"""
    
    print("ğŸš€ çœŸå®P2Læ¨¡å‹æµ‹è¯•")
    print("=" * 80)
    
    try:
        # å¯¼å…¥P2Lå¼•æ“
        from p2l_engine import P2LEngine
        from config import get_all_models
        
        print("âœ… æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºP2Lå¼•æ“
        print("ğŸ” æ­£åœ¨åŠ è½½P2Læ¨¡å‹...")
        engine = P2LEngine()
        
        print("âœ… çœŸå®P2Læ¨¡å‹å¼•æ“åˆ›å»ºæˆåŠŸï¼")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        model_info = engine.get_model_info()
        print(f"\nğŸ“Š ã€P2Læ¨¡å‹ä¿¡æ¯ã€‘")
        for key, value in model_info.items():
            if isinstance(value, list):
                print(f"   {key}: {len(value)} é¡¹")
                for item in value[:3]:  # åªæ˜¾ç¤ºå‰3é¡¹
                    print(f"     - {item}")
                if len(value) > 3:
                    print(f"     ... è¿˜æœ‰ {len(value) - 3} é¡¹")
            else:
                print(f"   {key}: {value}")
        
        # è·å–æˆ‘ä»¬é…ç½®çš„æ¨¡å‹
        our_models = get_all_models()
        our_model_names = list(our_models.keys())
        
        print(f"\nğŸ“‹ ã€æ¨¡å‹å¯¹æ¯”ã€‘")
        print(f"æˆ‘ä»¬é…ç½®çš„æ¨¡å‹: {len(our_model_names)} ä¸ª")
        print(f"P2Læ”¯æŒçš„æ¨¡å‹: {len(engine.get_supported_models())} ä¸ª")
        
        # æ£€æŸ¥æˆ‘ä»¬çš„æ¨¡å‹å“ªäº›è¢«P2Læ”¯æŒ
        supported_models = []
        unsupported_models = []
        
        for model_name in our_model_names:
            if engine.check_model_support(model_name):
                supported_models.append(model_name)
            else:
                unsupported_models.append(model_name)
        
        print(f"âœ… è¢«P2Læ”¯æŒçš„æ¨¡å‹: {len(supported_models)} ä¸ª")
        for model in supported_models[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"   - {model}")
        if len(supported_models) > 5:
            print(f"   ... è¿˜æœ‰ {len(supported_models) - 5} ä¸ª")
        
        if unsupported_models:
            print(f"âš ï¸ ä¸è¢«P2Læ”¯æŒçš„æ¨¡å‹: {len(unsupported_models)} ä¸ª")
            for model in unsupported_models[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"   - {model}")
            if len(unsupported_models) > 3:
                print(f"   ... è¿˜æœ‰ {len(unsupported_models) - 3} ä¸ª")
        
        # æµ‹è¯•ä¸åŒç±»å‹çš„æç¤ºè¯
        test_cases = [
            {
                "prompt": "å†™ä¸€ä¸ªPythonå¿«é€Ÿæ’åºç®—æ³•ï¼Œè¦æ±‚ä»£ç ç®€æ´é«˜æ•ˆ",
                "description": "ç¼–ç¨‹ä»»åŠ¡",
                "models": supported_models[:6] if len(supported_models) >= 6 else supported_models
            },
            {
                "prompt": "è¯·è§£é‡Šé‡å­è®¡ç®—çš„åŸºæœ¬åŸç†ï¼ŒåŒ…æ‹¬é‡å­æ¯”ç‰¹ã€å åŠ æ€å’Œçº ç¼ ç°è±¡",
                "description": "ç§‘å­¦è§£é‡Š",
                "models": supported_models[:5] if len(supported_models) >= 5 else supported_models
            },
            {
                "prompt": "å¸®æˆ‘ç¿»è¯‘è¿™æ®µè¯ï¼šThe future of artificial intelligence is bright.",
                "description": "ç¿»è¯‘ä»»åŠ¡",
                "models": supported_models[:4] if len(supported_models) >= 4 else supported_models
            }
        ]
        
        for i, test_case in enumerate(test_cases, 1):
            if not test_case["models"]:
                print(f"\nâš ï¸ è·³è¿‡æµ‹è¯•ç”¨ä¾‹ {i}ï¼šæ²¡æœ‰æ”¯æŒçš„æ¨¡å‹")
                continue
                
            print(f"\n" + "ğŸ§ª" + "=" * 79)
            print(f"ğŸ§ª æµ‹è¯•ç”¨ä¾‹ {i}: {test_case['description']}")
            print(f"ğŸ“ æç¤ºè¯: {test_case['prompt']}")
            print(f"ğŸ¯ æµ‹è¯•æ¨¡å‹: {len(test_case['models'])} ä¸ª")
            print("ğŸ§ª" + "=" * 79)
            
            try:
                # ä½¿ç”¨çœŸå®P2Læ¨¡å‹è®¡ç®—ç³»æ•°
                print(f"ğŸ” æ­£åœ¨ä½¿ç”¨çœŸå®P2Læ¨¡å‹è®¡ç®—Bradley-Terryç³»æ•°...")
                
                coefficients = engine.get_coefficients_for_prompt(
                    prompt=test_case["prompt"],
                    models=test_case["models"]
                )
                
                print(f"âœ… P2Læ¨ç†å®Œæˆï¼")
                print(f"ğŸ“Š è®¡ç®—äº† {len(coefficients.model_coefficients)} ä¸ªæ¨¡å‹çš„ç³»æ•°")
                print(f"ğŸ¯ Etaå‚æ•°: {coefficients.eta}")
                print(f"ğŸ¯ Gammaå‚æ•°: {coefficients.gamma}")
                
                # è·å–æ’å
                rankings = engine.get_model_rankings(coefficients)
                
                print(f"\nğŸ† ã€æ¨¡å‹æ’åã€‘(åŸºäºçœŸå®P2Lç³»æ•°)")
                for j, (model, coef) in enumerate(rankings[:5], 1):
                    confidence = coefficients.confidence_scores.get(model, 0.5)
                    print(f"   {j}. {model}")
                    print(f"      Bradley-Terryç³»æ•°: {coef:.4f}")
                    print(f"      ç½®ä¿¡åº¦åˆ†æ•°: {confidence:.3f}")
                
                # è®¡ç®—å‰ä¸¤åçš„å¯¹æˆ˜æ¦‚ç‡
                if len(rankings) >= 2:
                    model_a, coef_a = rankings[0]
                    model_b, coef_b = rankings[1]
                    
                    probs = engine.calculate_win_probabilities(
                        coefficients, 
                        [(model_a, model_b)]
                    )
                    
                    prob_data = probs[(model_a, model_b)]
                    
                    print(f"\nğŸ†š ã€å¯¹æˆ˜åˆ†æã€‘{model_a} vs {model_b}")
                    print(f"   {model_a} èƒœç‡: {prob_data['win']:.1%}")
                    print(f"   {model_b} èƒœç‡: {prob_data['lose']:.1%}")
                    print(f"   å¹³å±€æ¦‚ç‡: {prob_data['tie']:.1%}")
                    print(f"   åŒæ–¹éƒ½ä¸å¥½: {prob_data['tie_bothbad']:.1%}")
                
                # è·å–è°ƒè¯•ä¿¡æ¯
                debug_info = engine.get_debug_info(test_case["prompt"], test_case["models"])
                print(f"\nğŸ› ã€è°ƒè¯•ä¿¡æ¯ã€‘")
                print(f"   æ¨¡å‹è®¾å¤‡: {debug_info['model_device']}")
                print(f"   æ¨¡å‹ç²¾åº¦: {debug_info['model_dtype']}")
                print(f"   æç¤ºè¯é•¿åº¦: {debug_info['prompt_length']}")
                print(f"   å¤„ç†æ¨¡å‹æ•°: {debug_info['model_count']}")
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•ç”¨ä¾‹ {i} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        print(f"\n" + "=" * 80)
        print(f"ğŸ‰ çœŸå®P2Læ¨¡å‹æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ’¡ ç°åœ¨ä½ å¯ä»¥çœ‹åˆ°çœŸæ­£çš„P2L Bradley-Terryç³»æ•°äº†")
        print(f"ğŸš€ è¿™äº›ç³»æ•°æ˜¯ç”±è®­ç»ƒå¥½çš„P2Læ¨¡å‹æ ¹æ®æç¤ºè¯åŠ¨æ€è®¡ç®—çš„")
        
    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print(f"ğŸ’¡ è¯·ç¡®ä¿P2Lé¡¹ç›®è·¯å¾„æ­£ç¡®ï¼Œå¹¶ä¸”å·²å®‰è£…æ‰€éœ€ä¾èµ–")
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ çœŸå®P2Læ¨¡å‹æµ‹è¯•å¥—ä»¶")
    print("ğŸ¯ æ­¤è„šæœ¬å°†ä½¿ç”¨ä¸‹è½½çš„p2l-135m-grkæ¨¡å‹è¿›è¡ŒçœŸå®çš„Bradley-Terryç³»æ•°è®¡ç®—")
    print("=" * 80)
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_real_p2l_model())
    
    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ’¡ å¦‚æœæµ‹è¯•æˆåŠŸï¼Œè¯´æ˜çœŸå®P2Læ¨¡å‹å·²ç»å¯ä»¥æ­£å¸¸å·¥ä½œ")