#!/usr/bin/env python3
"""
ç³»ç»Ÿå®Œæ•´æ€§æµ‹è¯•è„šæœ¬
éªŒè¯å¤§æ¨¡å‹APIå¼•å…¥å’ŒP2Lå¼•æ“æ•´åˆæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import asyncio
import json

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, backend_dir)

def test_configurations():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("=== é…ç½®æµ‹è¯• ===")
    
    try:
        from config import get_p2l_config, get_api_config
        
        # æµ‹è¯•P2Lé…ç½®
        p2l_config = get_p2l_config()
        print(f"âœ… P2Lé…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹è·¯å¾„: {p2l_config['model_path']}")
        print(f"   è·¯å¾„å­˜åœ¨: {os.path.exists(p2l_config['model_path'])}")
        
        # æµ‹è¯•APIé…ç½®
        api_config = get_api_config()
        print(f"âœ… APIé…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æ”¯æŒçš„æä¾›å•†: {list(api_config['api_keys'].keys())}")
        
        # æ£€æŸ¥APIå¯†é’¥
        for provider, key in api_config['api_keys'].items():
            status = "âœ…" if key else "âŒ"
            print(f"   {provider}: {status}")
        
        return True
    except Exception as e:
        print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_p2l_engine():
    """æµ‹è¯•P2Lå¼•æ“"""
    print("\n=== P2Lå¼•æ“æµ‹è¯• ===")
    
    try:
        from p2l_engine import P2LEngine
        
        engine = P2LEngine()
        
        print(f"âœ… P2Lå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        
        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = engine.get_model_info()
        print(f"   æ”¯æŒæ¨¡å‹æ•°é‡: {model_info.get('supported_models', 0)}")
        print(f"   æ¨¡å‹æ¶æ„: {model_info.get('architecture', 'unknown')}")
        
        # æµ‹è¯•æ¨¡å‹æ”¯æŒæ£€æŸ¥
        test_models = ["gpt-4o-2024-08-06", "claude-3-5-sonnet-20241022", "invalid-model"]
        
        for model in test_models:
            supported = engine.check_model_support(model)
            status = "âœ…" if supported else "âŒ"
            print(f"   {model}: {status}")
        
        return True
    except Exception as e:
        print(f"âŒ P2Lå¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_p2l_service():
    """æµ‹è¯•P2LåŸç”ŸæœåŠ¡"""
    print("\n=== P2LåŸç”ŸæœåŠ¡æµ‹è¯• ===")
    
    try:
        from service_p2l_native import P2LNativeBackendService
        
        service = P2LNativeBackendService()
        print(f"âœ… P2LåŸç”ŸæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        print(f"   é…ç½®çš„æ¨¡å‹æ•°é‡: {len(service.all_models)}")
        print(f"   è®¾å¤‡: {service.device}")
        
        # æµ‹è¯•å¥åº·æ£€æŸ¥
        health = service.get_health_status()
        print(f"   å¥åº·çŠ¶æ€: {health['status']}")
        print(f"   æœåŠ¡ç±»å‹: {health.get('service_type', 'unknown')}")
        
        # æµ‹è¯•æ¨¡å‹åˆ—è¡¨
        models = service.get_available_models()
        print(f"   å¯ç”¨æ¨¡å‹: {len(models)} ä¸ª")
        
        return True
    except Exception as e:
        print(f"âŒ P2LåŸç”ŸæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("\n=== APIè¿æ¥æµ‹è¯• ===")
    
    try:
        import aiohttp
        
        # æµ‹è¯•é…ç½®
        test_configs = [
            {
                'name': 'yinli.one (OpenAI/Anthropic/Google)',
                'base_url': 'https://yinli.one/v1',
                'api_key': 'sk-u3kUo5WN8Ezb3U3pEx1GWTeazL7xNzghFErxNO4pkJHa4QPl'
            },
            {
                'name': 'probex.top (DeepSeek/Meta)',
                'base_url': 'https://api.probex.top/v1',
                'api_key': 'sk-LVXnQECvuyLW9kCpDLkGmw5nAi7zzJ6QcgofVi42Vy0CqVo9'
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            for config in test_configs:
                try:
                    headers = {'Authorization': f"Bearer {config['api_key']}"}
                    async with session.get(
                        f"{config['base_url']}/models",
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=10)
                    ) as response:
                        if response.status == 200:
                            data = await response.json()
                            model_count = len(data.get('data', []))
                            print(f"âœ… {config['name']}: {model_count} ä¸ªæ¨¡å‹")
                        else:
                            print(f"âŒ {config['name']}: HTTP {response.status}")
                except Exception as e:
                    print(f"âŒ {config['name']}: {e}")
        
        return True
    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_complete_flow():
    """æµ‹è¯•å®Œæ•´æµç¨‹"""
    print("\n=== å®Œæ•´æµç¨‹æµ‹è¯• ===")
    
    try:
        from unified_client import UnifiedLLMClient
        
        client = UnifiedLLMClient()
        
        test_prompt = "å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹"
        print(f"æµ‹è¯•æç¤º: {test_prompt}")
        
        # æµ‹è¯•å®¢æˆ·ç«¯åˆå§‹åŒ–
        print("âœ… ç»Ÿä¸€å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # éªŒè¯é…ç½®ï¼ˆä¸å®é™…è°ƒç”¨APIï¼‰
        print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å‘é€APIè¯·æ±‚")
        return True
            
    except Exception as e:
        print(f"âŒ å®Œæ•´æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç³»ç»Ÿå®Œæ•´æ€§æµ‹è¯•...\n")
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(("é…ç½®åŠ è½½", test_configurations()))
    results.append(("P2Lå¼•æ“", test_p2l_engine()))
    results.append(("P2LæœåŠ¡", test_p2l_service()))
    results.append(("APIè¿æ¥", await test_api_connection()))
    results.append(("å®Œæ•´æµç¨‹", await test_complete_flow()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        print("\nğŸ“‹ ç³»ç»Ÿé…ç½®æ‘˜è¦:")
        print("   â€¢ P2Læ¨¡å‹è·¯å¾„å·²æ›´æ–°åˆ° backend/model_p2l/models")
        print("   â€¢ APIé…ç½®æ­£ç¡®ï¼šyinli.one è´Ÿè´£ OpenAI/Anthropic/Google")
        print("   â€¢              probex.top è´Ÿè´£ DeepSeek/Meta")
        print("   â€¢ æ™ºèƒ½æ¨¡å‹é€‰æ‹©åŸºäºP2Lè¯­ä¹‰åˆ†æ")
        print("   â€¢ æ”¯æŒ21ä¸ªæ¨¡å‹ï¼Œ6ä¸ªAPIæä¾›å•†")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®ã€‚")

if __name__ == "__main__":
    asyncio.run(main())