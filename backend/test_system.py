#!/usr/bin/env python3
"""
ç³»ç»Ÿå®Œæ•´æ€§æµ‹è¯•è„šæœ¬
éªŒè¯å¤§æ¨¡å‹APIå¼•å…¥å’ŒP2Lå¼•æ“æ•´åˆæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import os
import asyncio
import json

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, '.')

def test_configurations():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("=== é…ç½®æµ‹è¯• ===")
    
    try:
        from config import get_p2l_config, get_api_config
        
        # æµ‹è¯•P2Lé…ç½®
        p2l_config = get_p2l_config()
        print(f"âœ… P2Lé…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æ¨¡å‹è·¯å¾„: {p2l_config['model_path']}")
        print(f"   è·¯å¾„å­˜åœ¨: {os.path.exists(p2l_config['model_path'])}")
        
        # æµ‹è¯•APIé…ç½®
        api_config = get_api_config()
        print(f"âœ… APIé…ç½®åŠ è½½æˆåŠŸ")
        print(f"   æ”¯æŒçš„æä¾›å•†: {list(api_config['api_keys'].keys())}")
        
        # æ£€æŸ¥APIå¯†é’¥
        for provider, key in api_config['api_keys'].items():
            status = "âœ…" if key else "âŒ"
            print(f"   {provider}: {status}")
        
        return True
    except Exception as e:
        print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_p2l_engine():
    """æµ‹è¯•P2Lå¼•æ“"""
    print("\n=== P2Lå¼•æ“æµ‹è¯• ===")
    
    try:
        from p2l_engine import P2LEngine
        import torch
        
        device = torch.device('cpu')
        engine = P2LEngine(device)
        
        print(f"âœ… P2Lå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
        print(f"   åŠ è½½çš„P2Læ¨¡å‹æ•°é‡: {len(engine.p2l_models)}")
        print(f"   æ¨ç†å¼•æ“çŠ¶æ€: {'å¯ç”¨' if engine.p2l_inference_engine else 'ä¸å¯ç”¨'}")
        
        # æµ‹è¯•è¯­ä¹‰åˆ†æ
        test_prompts = [
            "å†™ä¸€ä¸ªç®€å•çš„Pythonå‡½æ•°",
            "è®¾è®¡ä¸€ä¸ªå¤æ‚çš„æœºå™¨å­¦ä¹ ç®—æ³•æ¥é¢„æµ‹è‚¡ç¥¨ä»·æ ¼",
            "ç¿»è¯‘è¿™æ®µæ–‡å­—åˆ°ä¸­æ–‡"
        ]
        
        for prompt in test_prompts:
            complexity, language = engine.semantic_analysis(prompt)
            print(f"   '{prompt[:30]}...' -> å¤æ‚åº¦: {complexity:.3f}, è¯­è¨€: {language:.3f}")
        
        return True
    except Exception as e:
        print(f"âŒ P2Lå¼•æ“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_manager():
    """æµ‹è¯•æ¨¡å‹ç®¡ç†å™¨"""
    print("\n=== æ¨¡å‹ç®¡ç†å™¨æµ‹è¯• ===")
    
    try:
        from model_manager import ModelManager
        
        manager = ModelManager()
        print(f"âœ… æ¨¡å‹ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        print(f"   é…ç½®çš„æ¨¡å‹æ•°é‡: {len(manager.model_configs)}")
        
        # æµ‹è¯•æ¨¡å‹é€‰æ‹©
        test_cases = [
            ("ç®€å•ä»»åŠ¡", "å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ"),
            ("ä¸­ç­‰ä»»åŠ¡", "å®ç°ä¸€ä¸ªäºŒåˆ†æŸ¥æ‰¾ç®—æ³•"),
            ("å¤æ‚ä»»åŠ¡", "è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ ç®¡é“æ¥é¢„æµ‹æˆ¿ä»·")
        ]
        
        for task_type, prompt in test_cases:
            selected_model = manager.select_model(prompt)
            model_config = manager.get_model_config(selected_model)
            
            if model_config:
                provider = model_config['provider']
                api_config = manager.get_api_config(provider)
                print(f"   {task_type}: {selected_model} ({provider})")
                print(f"     APIç«¯ç‚¹: {api_config['base_url']}")
            else:
                print(f"   {task_type}: âŒ é…ç½®æœªæ‰¾åˆ°")
        
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹ç®¡ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("\n=== APIè¿æ¥æµ‹è¯• ===")
    
    try:
        import aiohttp
        
        # æµ‹è¯•é…ç½®
        test_configs = [
            {
                'name': 'yinli.one (OpenAI/Anthropic/Google)',
                'base_url': 'https://yinli.one/v1',
                'api_key': 'sk-u3kUo5WN8Ezb3U3pEx1GWTeazL7xNzghFErxNO4pkJHa4QPl'
            },
            {
                'name': 'probex.top (DeepSeek/Meta)',
                'base_url': 'https://api.probex.top/v1',
                'api_key': 'sk-LVXnQECvuyLW9kCpDLkGmw5nAi7zzJ6QcgofVi42Vy0CqVo9'
            }
        ]
        
        async with aiohttp.ClientSession() as session:
            for config in test_configs:
                try:
                    headers = {'Authorization': f"Bearer {config['api_key']}"}
                    async with session.get(
                        f"{config['base_url']}/models",
                        headers=headers,
                        timeout=aiohttp.ClientTimeout(total=10)
                    ) as response:
                        if response.status == 200:
                            data = await response.json()
                            model_count = len(data.get('data', []))
                            print(f"âœ… {config['name']}: {model_count} ä¸ªæ¨¡å‹")
                        else:
                            print(f"âŒ {config['name']}: HTTP {response.status}")
                except Exception as e:
                    print(f"âŒ {config['name']}: {e}")
        
        return True
    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

async def test_complete_flow():
    """æµ‹è¯•å®Œæ•´æµç¨‹"""
    print("\n=== å®Œæ•´æµç¨‹æµ‹è¯• ===")
    
    try:
        from unified_client import UnifiedLLMClient
        from model_manager import ModelManager
        
        manager = ModelManager()
        client = UnifiedLLMClient()
        
        test_prompt = "å†™ä¸€ä¸ªPythonå‡½æ•°è®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„ç¬¬né¡¹"
        print(f"æµ‹è¯•æç¤º: {test_prompt}")
        
        # é€‰æ‹©æ¨¡å‹
        selected_model = manager.select_model(test_prompt)
        print(f"é€‰æ‹©çš„æ¨¡å‹: {selected_model}")
        
        # è·å–é…ç½®
        model_config = manager.get_model_config(selected_model)
        if model_config:
            provider = model_config['provider']
            api_config = manager.get_api_config(provider)
            print(f"æä¾›å•†: {provider}")
            print(f"APIç«¯ç‚¹: {api_config['base_url']}")
            
            # å‘é€è¯·æ±‚ï¼ˆç®€åŒ–ç‰ˆï¼Œä¸å®é™…è°ƒç”¨APIï¼‰
            print("âœ… é…ç½®éªŒè¯é€šè¿‡ï¼Œå¯ä»¥å‘é€APIè¯·æ±‚")
            return True
        else:
            print("âŒ æœªæ‰¾åˆ°æ¨¡å‹é…ç½®")
            return False
            
    except Exception as e:
        print(f"âŒ å®Œæ•´æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ç³»ç»Ÿå®Œæ•´æ€§æµ‹è¯•...\n")
    
    results = []
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    results.append(("é…ç½®åŠ è½½", test_configurations()))
    results.append(("P2Lå¼•æ“", test_p2l_engine()))
    results.append(("æ¨¡å‹ç®¡ç†å™¨", test_model_manager()))
    results.append(("APIè¿æ¥", await test_api_connection()))
    results.append(("å®Œæ•´æµç¨‹", await test_complete_flow()))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "="*50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        print("\nğŸ“‹ ç³»ç»Ÿé…ç½®æ‘˜è¦:")
        print("   â€¢ P2Læ¨¡å‹è·¯å¾„å·²æ›´æ–°åˆ° backend/model_p2l/models")
        print("   â€¢ APIé…ç½®æ­£ç¡®ï¼šyinli.one è´Ÿè´£ OpenAI/Anthropic/Google")
        print("   â€¢              probex.top è´Ÿè´£ DeepSeek/Meta")
        print("   â€¢ æ™ºèƒ½æ¨¡å‹é€‰æ‹©åŸºäºP2Lè¯­ä¹‰åˆ†æ")
        print("   â€¢ æ”¯æŒ21ä¸ªæ¨¡å‹ï¼Œ6ä¸ªAPIæä¾›å•†")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³é…ç½®ã€‚")

if __name__ == "__main__":
    asyncio.run(main())