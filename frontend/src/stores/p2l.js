import { defineStore } from 'pinia'
import { p2lApi } from '@/utils/api'

export const useP2LStore = defineStore('p2l', {
  state: () => ({
    // ç³»ç»ŸçŠ¶æ€
    backendHealth: false,
    loading: false,
    
    // é…ç½®ç‰ˆæœ¬ï¼ˆç”¨äºæ£€æµ‹é…ç½®æ›´æ–°ï¼‰
    configVersion: '2.0.1', // æ›´æ–°ç‰ˆæœ¬å·ä»¥å¼ºåˆ¶åˆ·æ–°é…ç½®
    
    // P2Låˆ†æç»“æœ
    currentAnalysis: null,
    recommendations: [],
    
    // èŠå¤©å†å²
    chatHistory: [],
    
    // æ¨¡å‹ä¿¡æ¯ - ä»åç«¯APIåŠ¨æ€è·å–
    availableModels: [],
    
    // å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨
    enabledModels: [],
    
    // ä¼˜å…ˆæ¨¡å¼
    priorityMode: 'balanced'
  }),

  getters: {
    isBackendReady: (state) => state.backendHealth,
    
    getModelByName: (state) => (name) => {
      return state.availableModels.find(model => model.name === name)
    },
    
    // è¿‡æ»¤åçš„æ¨èç»“æœï¼ˆåªæ˜¾ç¤ºå¯ç”¨çš„æ¨¡å‹ï¼‰
    sortedRecommendations: (state) => {
      return [...state.recommendations]
        .filter(rec => state.enabledModels.includes(rec.model))
        .sort((a, b) => b.score - a.score)
    },
    
    // å¯ç”¨çš„æ¨¡å‹ä¿¡æ¯
    enabledModelInfos: (state) => {
      return state.availableModels.filter(model => 
        state.enabledModels.includes(model.name)
      )
    }
  },

  actions: {
    // æ£€æŸ¥åç«¯å¥åº·çŠ¶æ€
    async checkBackendHealth() {
      try {
        const response = await p2lApi.get('/health')
        this.backendHealth = response.status === 200
        return this.backendHealth
      } catch (error) {
        console.error('åç«¯æœåŠ¡æ£€æŸ¥å¤±è´¥:', error)
        this.backendHealth = false
        return false
      }
    },

    // ä»åç«¯è·å–æ¨¡å‹åˆ—è¡¨
    async loadModelsFromBackend() {
      try {
        const response = await p2lApi.get('/models')
        const backendData = response.data
        
        // å¤„ç†åç«¯è¿”å›çš„æ•°æ®æ ¼å¼ {models: [...], total: 42}
        const modelNames = backendData.models || []
        
        // è½¬æ¢æ¨¡å‹åç§°ä¸ºå‰ç«¯æ ¼å¼
        this.availableModels = modelNames.map(name => ({
          name,
          provider: this.getProviderDisplayName(this.getProviderFromModelName(name)),
          type: this.getModelType(name),
          cost: this.getCostLevel(this.estimateCostFromModelName(name)),
          speed: this.getSpeedLevel(this.estimateSpeedFromModelName(name)),
          hasApiKey: true
        }))
        
        console.log(`âœ… ä»åç«¯åŠ è½½äº† ${this.availableModels.length} ä¸ªæ¨¡å‹`)
        return this.availableModels
      } catch (error) {
        console.error('ä»åç«¯è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error)
        // å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤çš„å‡ ä¸ªä¸»è¦æ¨¡å‹
        this.availableModels = [
          { name: 'gpt-4o', provider: 'OpenAI', type: 'GPT', cost: 'é«˜', speed: 'ä¸­', hasApiKey: true },
          { name: 'claude-3-5-sonnet-20241022', provider: 'Anthropic', type: 'Claude', cost: 'é«˜', speed: 'ä¸­', hasApiKey: true },
          { name: 'gemini-1.5-pro', provider: 'Google', type: 'Gemini', cost: 'ä¸­', speed: 'ä¸­', hasApiKey: true }
        ]
        return this.availableModels
      }
    },

    // è¾…åŠ©æ–¹æ³•ï¼šä»æ¨¡å‹åç§°æ¨æ–­æä¾›å•†
    getProviderFromModelName(modelName) {
      if (modelName.includes('gpt') || modelName.includes('o1')) return 'openai'
      if (modelName.includes('claude')) return 'anthropic'
      if (modelName.includes('gemini')) return 'google'
      if (modelName.includes('deepseek')) return 'deepseek'
      if (modelName.includes('qwen')) return 'qwen'
      if (modelName.includes('llama')) return 'meta'
      if (modelName.includes('yi')) return 'yi'
      return 'unknown'
    },

    // è¾…åŠ©æ–¹æ³•ï¼šè·å–æä¾›å•†æ˜¾ç¤ºåç§°
    getProviderDisplayName(provider) {
      const providerMap = {
        'openai': 'OpenAI',
        'anthropic': 'Anthropic', 
        'google': 'Google',
        'deepseek': 'DeepSeek',
        'qwen': 'åƒé—®',
        'meta': 'Meta',
        'yi': 'é›¶ä¸€ä¸‡ç‰©',
        'yinli': 'yinliä»£ç†',
        'probex': 'ProbeXä»£ç†',
        'unknown': 'æœªçŸ¥'
      }
      return providerMap[provider] || provider
    },

    // è¾…åŠ©æ–¹æ³•ï¼šä»æ¨¡å‹åç§°ä¼°ç®—æˆæœ¬
    estimateCostFromModelName(modelName) {
      if (modelName.includes('o1') || modelName.includes('gpt-4')) return 0.015
      if (modelName.includes('claude-3-opus')) return 0.015
      if (modelName.includes('claude') || modelName.includes('gemini-1.5-pro')) return 0.01
      if (modelName.includes('gpt-4o-mini') || modelName.includes('deepseek') || modelName.includes('qwen')) return 0.002
      if (modelName.includes('gemini-1.5-flash')) return 0.001
      return 0.005
    },

    // è¾…åŠ©æ–¹æ³•ï¼šä»æ¨¡å‹åç§°ä¼°ç®—é€Ÿåº¦
    estimateSpeedFromModelName(modelName) {
      if (modelName.includes('turbo') || modelName.includes('flash') || modelName.includes('mini')) return 0.8
      if (modelName.includes('deepseek') || modelName.includes('qwen')) return 1.0
      if (modelName.includes('o1') || modelName.includes('opus')) return 3.0
      return 1.5
    },

    // è¾…åŠ©æ–¹æ³•ï¼šè·å–æ¨¡å‹ç±»å‹
    getModelType(modelName) {
      if (modelName.includes('gpt')) return 'GPT'
      if (modelName.includes('claude')) return 'Claude'
      if (modelName.includes('gemini')) return 'Gemini'
      if (modelName.includes('deepseek')) return 'DeepSeek'
      if (modelName.includes('qwen')) return 'Qwen'
      return 'LLM'
    },

    // è¾…åŠ©æ–¹æ³•ï¼šè·å–æˆæœ¬ç­‰çº§
    getCostLevel(costPer1k) {
      if (costPer1k <= 0.001) return 'æä½'
      if (costPer1k <= 0.005) return 'ä½'
      if (costPer1k <= 0.015) return 'ä¸­'
      return 'é«˜'
    },

    // è¾…åŠ©æ–¹æ³•ï¼šè·å–é€Ÿåº¦ç­‰çº§
    getSpeedLevel(responseTime) {
      if (responseTime <= 1.0) return 'å¿«'
      if (responseTime <= 2.0) return 'ä¸­'
      return 'æ…¢'
    },

    // P2Læ™ºèƒ½åˆ†æ
    async analyzeWithP2L(prompt, mode = 'balanced') {
      this.loading = true
      try {
        console.log('ğŸš€ [P2L Store] å‘é€è¯·æ±‚:', { prompt: prompt.substring(0, 50), priority: mode })
        
        const response = await p2lApi.post('/p2l/analyze', {
          prompt,
          priority: mode, // ä¿®æ­£å‚æ•°å
          enabled_models: this.enabledModels.length > 0 ? this.enabledModels : this.availableModels.map(m => m.name)
        })
        
        console.log('ğŸ“¥ [P2L Store] åç«¯è¿”å›æ•°æ®:', {
          routing_info: response.data.routing_info,
          strategy: response.data.routing_info?.strategy,
          full_response: response.data
        })
        
        this.currentAnalysis = response.data
        this.recommendations = response.data.recommendations || []
        
        return response.data
      } catch (error) {
        console.error('P2Låˆ†æå¤±è´¥:', error)
        throw new Error('P2Låˆ†ææœåŠ¡æš‚æ—¶ä¸å¯ç”¨')
      } finally {
        this.loading = false
      }
    },

    // è°ƒç”¨LLMç”Ÿæˆå›ç­”
    async generateWithLLM(model, prompt, conversationHistory = []) {
      this.loading = true
      try {
        // æ„å»ºæ¶ˆæ¯å†å²ï¼ŒåŒ…å«å®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡
        const messages = []
        
        // æ·»åŠ å†å²å¯¹è¯è®°å½• - ä¿®å¤ç©ºå†…å®¹é—®é¢˜
        conversationHistory.forEach(item => {
          // åªæ·»åŠ éç©ºçš„ç”¨æˆ·æ¶ˆæ¯
          if (item.prompt && item.prompt.trim()) {
            messages.push({
              role: 'user',
              content: item.prompt.trim()
            })
          }
          // åªæ·»åŠ éç©ºçš„åŠ©æ‰‹å›å¤
          if (item.response && item.response.trim()) {
            messages.push({
              role: 'assistant', 
              content: item.response.trim()
            })
          }
        })
        
        // æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
        messages.push({
          role: 'user',
          content: prompt
        })
        
        const response = await p2lApi.post('/llm/generate', {
          model,
          prompt,
          messages, // ä¼ é€’å®Œæ•´çš„å¯¹è¯å†å²
          max_tokens: 2000
        })
        
        // æ£€æŸ¥åç«¯æ˜¯å¦è¿”å›äº†é”™è¯¯çŠ¶æ€
        if (response.data.provider === 'error') {
          throw new Error(response.data.content || response.data.response || 'LLMæœåŠ¡è°ƒç”¨å¤±è´¥')
        }
        
        const result = {
          id: Date.now(),
          prompt,
          model,
          response: response.data.response || response.data.content || 'æš‚æ— å›å¤å†…å®¹',
          timestamp: new Date(),
          cost: response.data.cost || 0,
          tokens: response.data.tokens || response.data.tokens_used || 0,
          provider: response.data.provider || 'unknown',
          responseTime: response.data.response_time || 0  // æ·»åŠ å“åº”æ—¶é—´
        }
        
        this.chatHistory.push(result)
        return result
      } catch (error) {
        console.error('LLMè°ƒç”¨å¤±è´¥:', error)
        
        // å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯æˆ–è¶…æ—¶ï¼Œæä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        if (error.code === 'ECONNABORTED' || error.message.includes('timeout')) {
          throw new Error(`${model} å“åº”è¶…æ—¶ï¼Œç¼–ç¨‹é—®é¢˜å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´å¤„ç†ï¼Œè¯·ç¨åé‡è¯•`)
        } else if (error.response?.status >= 500) {
          throw new Error(`${model} æœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•`)
        } else {
          throw new Error(error.message || `${model} æœåŠ¡æš‚æ—¶ä¸å¯ç”¨`)
        }
      } finally {
        this.loading = false
      }
    },

    // è®¾ç½®ä¼˜å…ˆæ¨¡å¼
    setPriorityMode(mode) {
      this.priorityMode = mode
    },

    // è®¾ç½®å¯ç”¨çš„æ¨¡å‹
    setEnabledModels(models) {
      this.enabledModels = models
      // ä¿å­˜åˆ°localStorage
      localStorage.setItem('p2l_enabled_models', JSON.stringify(models))
    },

    // åˆå§‹åŒ–å¯ç”¨çš„æ¨¡å‹ï¼ˆä»localStorageåŠ è½½æˆ–é»˜è®¤å…¨éƒ¨å¯ç”¨ï¼‰
    async initializeEnabledModels() {
      try {
        // é¦–å…ˆä»åç«¯åŠ è½½æ¨¡å‹åˆ—è¡¨
        await this.loadModelsFromBackend()
        
        // æ£€æŸ¥é…ç½®ç‰ˆæœ¬ï¼Œå¦‚æœç‰ˆæœ¬ä¸åŒ¹é…åˆ™æ¸…é™¤æ—§é…ç½®
        const savedVersion = localStorage.getItem('p2l_config_version')
        if (savedVersion !== this.configVersion) {
          console.log(`é…ç½®ç‰ˆæœ¬æ›´æ–° (${savedVersion} -> ${this.configVersion})ï¼Œæ¸…é™¤æ—§é…ç½®...`)
          localStorage.removeItem('p2l_enabled_models')
          localStorage.setItem('p2l_config_version', this.configVersion)
        }
        
        const saved = localStorage.getItem('p2l_enabled_models')
        if (saved) {
          const savedModels = JSON.parse(saved)
          // è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„æ¨¡å‹
          const validModels = savedModels.filter(modelName => 
            this.availableModels.some(m => m.name === modelName)
          )
          
          // å¦‚æœæœ‰æ•ˆæ¨¡å‹æ•°é‡ä¸åŒï¼Œè¯´æ˜æœ‰æ—§æ¨¡å‹è¢«ç§»é™¤æˆ–æ–°æ¨¡å‹è¢«æ·»åŠ ï¼Œéœ€è¦æ›´æ–°
          if (validModels.length !== savedModels.length) {
            console.log('æ£€æµ‹åˆ°è¿‡æ—¶çš„æ¨¡å‹é…ç½®ï¼Œæ­£åœ¨æ›´æ–°...')
            // æ·»åŠ æ–°æ¨¡å‹åˆ°å¯ç”¨åˆ—è¡¨
            const currentModelNames = this.availableModels.map(m => m.name)
            const newModels = currentModelNames.filter(name => !validModels.includes(name))
            this.enabledModels = [...validModels, ...newModels]
            // ä¿å­˜æ›´æ–°åçš„é…ç½®
            this.setEnabledModels(this.enabledModels)
          } else {
            this.enabledModels = validModels
          }
        } else {
          // é»˜è®¤å¯ç”¨æ‰€æœ‰æ¨¡å‹
          this.enabledModels = this.availableModels.map(m => m.name)
          this.setEnabledModels(this.enabledModels)
        }
        
        console.log(`âœ… åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨äº† ${this.enabledModels.length} ä¸ªæ¨¡å‹`)
      } catch (error) {
        console.error('åˆå§‹åŒ–æ¨¡å‹é…ç½®å¤±è´¥:', error)
        // å¦‚æœåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if (this.availableModels.length > 0) {
          this.enabledModels = this.availableModels.map(m => m.name)
          this.setEnabledModels(this.enabledModels)
        }
      }
    },

    // æ¸…ç©ºèŠå¤©å†å²
    clearChatHistory() {
      this.chatHistory = []
      this.currentAnalysis = null
      this.recommendations = []
    }
  }
})